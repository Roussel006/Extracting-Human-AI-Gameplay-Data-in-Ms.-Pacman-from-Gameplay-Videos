We present a code to extract gameplay information (all states and actions) in Ms. Pacman from videos of gameplay. We demonstrate the code on the Atari-HEAD dataset by Zhang et al (2020) that provides the gameplay information as a series of images (AKA, "videos").

The extracted gameplay data and all data from the Atari-HEAD dataset were combined into one datafile, which can be found here: https://osf.io/rd35j/
Original dataset by Zhang et al (2020) can be found here: https://zenodo.org/records/3451402

[In progress, notebooks and codes to be uploaded soon, before July 31, 2024]

References:
Zhang, R., Walshe, C., Liu, Z., Guan, L., Muller, K., Whritner, J., . . . Ballard, D. (2020). Atari-HEAD: Atari human eye-tracking and demonstration dataset. In *Proceedings of the AAAI conference on artificial intelligence* (Vol. 34, pp. 6811â€“6820). AAAI.
